## Rol para la configuración de kubernetes, en este caso en master ##

# Permitir acceso a puertos 
- name: configure master kubernetes
  become: true  
  ansible.posix.firewalld: 
    permanent: yes
    port: "{{item}}"
    state: enabled
  loop:
   - 6443/tcp
   - 2379-2380/tcp
   - 10250/tcp
   - 10251/tcp
   - 10252/tcp
   - 10255/tcp
   - 8285/udp
   - 8472/udp
   - 30000-32767/tcp
     
- name: configure kudeadm
  become: true  
  command: "{{item}}" 
  with_items:
   - kubeadm config images pull
       
# permitir accesso a workers 10.0.1.10/32, 10.0.1.11/32 y master 10.0.1.50
# la ip por defecto de la dirección de red del inteface de docker (172.17.0.1)
- name: permit access to workers and access container to localhost  
  become: true
  ansible.posix.firewalld:
    zone: public
    permanent: yes
    rich_rule: "{{item}}"
    state: enabled
  with_items:   
   - 'rule family=ipv4 source address=10.0.1.50/32 accept'
   - 'rule family=ipv4 source address=10.0.1.10/32 accept'
   - 'rule family=ipv4 source address=10.0.1.11/32 accept'
   - 'rule family=ipv4 source address=172.17.0.1/16 accept'
   - 'rule family=ipv4 source address=10.244.0.1/16 accept'
   - 'rule family=ipv4 source address=10.96.0.1/32 accept'
 
# volvemos a cargar el firewall
- name: access container to localhost  
  become: true
  command: "firewall-cmd --reload"
 
# obtenemos información del cluster, para saber si se puede conectar o no. 
# activo ignore_errors para que no pare la ejecución si el cluster no existiera
- name: Obtain cluster_info
  become: true
  command: "kubectl cluster-info dump"
  register: cluster_info
  ignore_errors: yes
     
# definimos la red de los pods mientras pueda conectarse
- name: Define POD net cidr
  become: true
  command: "kubeadm init --pod-network-cidr 10.244.0.0/16"
  when: cluster_info.stderr | length > 0

# usuario root
- name: Create .kube directory
  become: true
  ansible.builtin.file:
    path: /root/.kube
    state: directory
    mode: "0700"

- name: Copy kubernetes config
  become: true
  ansible.builtin.copy:
    src: /etc/kubernetes/admin.conf
    dest: /root/.kube/config
    owner: root
    group: root
    mode: "0600"
    remote_src: yes

# usuario de ansible
- name: Create User .kube directory
  ansible.builtin.file:
    path: /home/{{ ansible_user }}/.kube
    state: directory
    mode: "0700"

- name: Copy User kubernetes config
  become: true
  ansible.builtin.copy:
    src: /etc/kubernetes/admin.conf
    dest: /home/{{ ansible_user }}/config
    owner: "{{ ansible_user }}"
    group: "{{ ansible_user }}"
    mode: "0600"
    remote_src: yes

# instalar el CNI, flannel
- name: install CNI
  shell: |
    kubectl apply -f https://raw.githubusercontent.com/coreos/flannel/master/Documentation/kube-flannel.yml

# obtenemos el join command para conectarnos al cluster, nos hará falta este token_join para enlazar en los workers
- name: Get token
  shell: kubeadm token create --print-join-command
  register: token_join
     
# autorizar al usuario ansible acceder al cluster
- name: Create .kube directory
  become: true
  file:
    path: /home/{{ ansible_user }}/.kube
    owner: "{{ ansible_user }}"
    group: "{{ ansible_user }}"
    state: directory
       
# copiamos config al usuario ansible
- name: Copy k8s config
  become: true
  copy:
    src: /etc/kubernetes/admin.conf
    dest: /home/{{ ansible_user }}/.kube/config
    owner: "{{ ansible_user }}"
    group: "{{ ansible_user }}"
    remote_src: yes
   
# autorizar al usuario root acceder al cluster
- name: Create .kube root directory
  become: true
  file:
    path: /root/.kube
    owner: "root"
    group: "root"
    state: directory

# copiamos config al usuario root
- name: Copy k8s to root config
  become: true
  copy:
    src: /etc/kubernetes/admin.conf
    dest: /root/.kube/config
    owner: "root"
    group: "root"
    remote_src: yes
   

     
